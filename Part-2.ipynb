{"cells":[{"cell_type":"markdown","metadata":{"id":"cepFW7GpT3nK"},"source":["# Set-up"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i11Wt0wITajQ","trusted":true},"outputs":[],"source":["import numpy as np\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from tensorflow.keras.applications.resnet50 import ResNet50\n","from tensorflow.keras.applications import VGG19\n","import tensorflow as tf\n","import tensorflow_hub as hub\n","import tensorflow_datasets as tfds\n","\n","from sklearn.metrics import ConfusionMatrixDisplay\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import precision_recall_curve\n","from sklearn.metrics import PrecisionRecallDisplay\n","from sklearn.metrics import average_precision_score\n","from sklearn.metrics import roc_curve\n","from sklearn.metrics import RocCurveDisplay\n","from sklearn.metrics import auc\n","from sklearn.model_selection import train_test_split\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import os\n","import cv2\n","import time\n","import itertools\n","\n","import scipy.io \n","from scipy.ndimage.filters import gaussian_filter\n","from scipy.ndimage.interpolation import map_coordinates\n","from scipy.ndimage import rotate\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mqHRE2Q-FNka","trusted":true},"outputs":[],"source":["def show_img(image):\n","  plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n","  plt.show()\n","\n","IMAG_SIZE = 224 # All images will be resized to 224x224\n","def normalize_img(image, label):\n","  image = tf.cast(image, tf.float32)\n","  image = (image/127.5) - 1\n","  image = tf.image.resize(image, (IMAG_SIZE, IMAG_SIZE))\n","  return  image, label"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UYDO_RaVY-fA","outputId":"f6c0ddc3-64c4-4646-cfe7-0194644a6f4b","trusted":true},"outputs":[],"source":["(raw_train, raw_validation, raw_test), metadata = tfds.load(\n","    name=\"oxford_flowers102\",\n","    split=['train', 'validation', 'test'],\n","    with_info=True,\n","    as_supervised=True,\n","    batch_size=32\n",")\n","\n","train = raw_train.map(normalize_img)\n","validation = raw_validation.map(normalize_img)\n","test = raw_test.map(normalize_img)\n","\n","print(metadata.splits[\"train\"].num_examples)\n","print(metadata.splits[\"validation\"].num_examples)\n","print(metadata.splits[\"test\"].num_examples)"]},{"cell_type":"markdown","metadata":{"id":"eiyQD6TcY7aQ"},"source":["# Model Training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-2Xa6H2yZav6","trusted":true},"outputs":[],"source":["NUM_CLASSES = 102\n","input_shape = (224,224,3)\n","\n","pixels = 224\n","IMAGE_SIZE = (pixels, pixels)\n","\n","# below you can see the two models we use transfer learning on.\n","# the first is a version of mobileNet and second resNet50.\n","# for both we create a model and continue training them on the flowers102 dataset\n","\"\"\"\n","#################################################################################################\n","    MobileNet\n","#################################################################################################\n","\"\"\"\n","\n","handle_base = \"mobilenet_v2_100_224\"\n","MODULE_HANDLE =\"https://tfhub.dev/google/imagenet/{}/feature_vector/4\".format(handle_base)\n","\n","mobileNet_fine_tuning = True\n","mobilenet = tf.keras.Sequential([\n","    hub.KerasLayer(MODULE_HANDLE, trainable=mobileNet_fine_tuning),\n","    tf.keras.layers.Dropout(rate=0.2),\n","    tf.keras.layers.Dense(units=metadata.features[\"label\"].num_classes)\n","])\n","mobilenet.build((None,)+IMAGE_SIZE+(3,))\n","mobilenet.summary()\n","\n","\"\"\"\n","#################################################################################################\n","    ResNet\n","#################################################################################################\n","\"\"\"\n","\n","resNet_fine_tuning = True\n","ResNet_model = keras.Sequential([\n","    ResNet50(include_top = False, pooling = 'avg', weights = 'imagenet',input_shape=input_shape),\n","    layers.Dense(30, activation = 'relu'),\n","    tf.keras.layers.Dropout(rate=0.2),\n","    tf.keras.layers.Dense(units=metadata.features[\"label\"].num_classes)\n","])\n","ResNet_model.layers[0].trainable = True\n","ResNet_model.build((None,)+IMAGE_SIZE+(3,))\n","ResNet_model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["BATCH_SIZE = 16\n","EPOCHS = 40\n","\n","steps_per_epoch = metadata.splits[\"train\"].num_examples / BATCH_SIZE \n","validation_steps = metadata.splits[\"validation\"].num_examples / BATCH_SIZE\n","\n","# Unbatch datasets to avoid batch mismatch\n","train = train.unbatch().batch(BATCH_SIZE,drop_remainder=True).repeat().shuffle(512)\n","validation = validation.unbatch().batch(BATCH_SIZE,drop_remainder=True).repeat()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_6c3nV0PVXOU","outputId":"05392fbd-0330-4c9d-dfff-a1b4f18df60e","trusted":true},"outputs":[],"source":["mobilenet.compile(\n","  optimizer=tf.keras.optimizers.Adam(learning_rate=.5e-3), \n","  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","  metrics=['accuracy'])\n","\n","mobilenet.fit(\n","    x=train,\n","    epochs=EPOCHS, \n","    steps_per_epoch=steps_per_epoch,\n","    validation_data=validation,\n","    validation_steps=validation_steps,\n","    verbose=2).history\n","\n","mobileNet_score = mobilenet.evaluate(x=test)\n","print(\"\")\n","print(\"Test loss:\", mobileNet_score[0])\n","print(\"Test accuracy:\", mobileNet_score[1])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QocSvhlXhY2H"},"outputs":[],"source":["mobilenet.save(\"mobileNet_model\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["ResNet_model.compile(\n","    optimizer=tf.keras.optimizers.Adam(learning_rate=.5e-3),\n","    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n","    metrics=[\"accuracy\"])\n","\n","ResNet_model.fit(\n","    x=train,\n","    epochs=EPOCHS, \n","    steps_per_epoch=steps_per_epoch,\n","    validation_data=validation,\n","    validation_steps=validation_steps,\n","    verbose=2).history\n","\n","ResNet_score = ResNet_model.evaluate(x=test, verbose=0)\n","\n","print(\"\")\n","print(\"Test loss:\", ResNet_score[0])\n","print(\"Test accuracy:\", ResNet_score[1])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Saving the model \n","ResNet_model.save(\"resNet_model\")"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
